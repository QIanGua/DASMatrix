#!/usr/bin/env python3
"""DAS Cleaning Agent æ¼”ç¤ºç¤ºä¾‹ã€‚

å±•ç¤º Cleaning Agent çš„æ ¸å¿ƒå·¥ä½œæµï¼šè¯Šæ–­ -> æ²»ç–— -> éªŒè¯ã€‚
"""

import json
from pathlib import Path

import h5py
import numpy as np


def create_noisy_data(path: Path) -> Path:
    """åˆ›å»ºåŒ…å«å„ç§å™ªå£°çš„åˆæˆ DAS æ•°æ®ã€‚"""
    fs = 1000
    duration = 2
    n_channels = 100
    n_samples = fs * duration
    t = np.arange(n_samples) / fs

    data = np.zeros((n_samples, n_channels))

    for ch in range(n_channels):
        # 1. åŸºç¡€ä¿¡å· (20Hz)
        signal = np.sin(2 * np.pi * 20 * t)

        # 2. æ·»åŠ è¶‹åŠ¿ (Trend)
        trend = np.linspace(0, 5, n_samples)

        # 3. æ·»åŠ  50Hz å·¥é¢‘å¹²æ‰°
        powerline = 0.5 * np.sin(2 * np.pi * 50 * t)

        # 4. éšæœºå™ªå£°
        noise = 0.2 * np.random.randn(n_samples)

        data[:, ch] = signal + trend + powerline + noise

    # 5. æ·»åŠ åé“ (Dead Channel & Noisy Channel)
    data[:, 10] = 0.0  # Dead
    data[:, 20] = data[:, 20] * 100  # Noisy

    with h5py.File(path, "w") as f:
        f.create_dataset("data", data=data)
        f.attrs["sampling_rate"] = fs

    print(f"âœ… åˆ›å»ºå™ªå£°æ•°æ®: {path}")
    return path


def demo_cleaning_workflow():
    print("\n" + "=" * 60)
    print("ğŸ§¹ DAS Cleaning Agent å·¥ä½œæµæ¼”ç¤º")
    print("=" * 60)

    from DASMatrix.agent import DASAgentTools

    tools = DASAgentTools()
    data_path = create_noisy_data(Path("/tmp/das_noisy_demo.h5"))

    # 1. è¯»å–æ•°æ®
    print("\n[Step 1] è¯»å–æ•°æ®...")
    res_read = tools.read_das_data(str(data_path))
    data_id = res_read["id"]
    print(f"   -> Data Loaded: {data_id}")

    # 2. è¯Šæ–­ (Diagnosis)
    print("\n[Step 2] è¯Šæ–­æ•°æ®è´¨é‡...")
    quality = tools.assess_data_quality(data_id)
    print(f"   -> è¯Šæ–­æŠ¥å‘Š:\n{json.dumps(quality, indent=4)}")

    # æ¨¡æ‹Ÿ Agent æ€è€ƒ
    print("\nğŸ¤– Agent æ€è€ƒ: å‘ç°æ˜æ˜¾è¶‹åŠ¿é¡¹ (has_trend=True) å’Œ 50Hz å¹²æ‰°ã€‚")
    print("              å­˜åœ¨åé“ (Idx: 10, 20)ã€‚")
    print(
        "              å»ºè®®æ–¹æ¡ˆ: ä½¿ç”¨ standard_denoise å»é™¤è¶‹åŠ¿ï¼Œé¢å¤–æ·»åŠ  50Hz æ»¤æ³¢ã€‚"
    )

    # 3. æ²»ç–— (Treatment)
    print("\n[Step 3] æ‰§è¡Œæ¸…æ´—...")

    # 3.1 åº”ç”¨æ ‡å‡†å»å™ªå¥—é¤
    res_clean1 = tools.apply_cleaning_recipe(data_id, "standard_denoise")
    clean_id = res_clean1["id"]
    print(f"   -> åº”ç”¨ standard_denoise: {clean_id}")

    # 3.2 é’ˆå¯¹æ€§å»é™¤ 50Hz (ç”±äº apply_cleaning_recipe æš‚æœªåŒ…å«ä¸“ç”¨ notchï¼Œæˆ‘ä»¬æ‰‹åŠ¨è°ƒç”¨ process_signal æ¨¡æ‹Ÿ)
    # real agent would call this if recipe wasn't enough, or we verify apply_cleaning_recipe("remove_powerline")

    # è®©æˆ‘ä»¬è¯•è¯• apply_cleaning_recipe çš„ remove_powerline (å½“å‰å®ç°æ˜¯ detrendï¼Œæ¨¡æ‹Ÿæ•ˆæœ)
    # æˆ–è€…æ‰‹åŠ¨è°ƒç”¨ process_signal
    # ä¸ºäº†æ¼”ç¤ºæ•ˆæœï¼Œæˆ‘ä»¬å‡è®¾ standard_denoise å·²ç»åšå¾—ä¸é”™äº†ï¼Œé™¤äº†å·¥é¢‘

    # 4. éªŒè¯ (Verification)
    print("\n[Step 4] éªŒè¯æ¸…æ´—ç»“æœ...")
    quality_after = tools.assess_data_quality(clean_id)
    print(f"   -> æ¸…æ´—åæŠ¥å‘Š:\n{json.dumps(quality_after, indent=4)}")

    # å¯¹æ¯”
    snr_before = quality.get("snr_estimate_db", 0)
    snr_after = quality_after.get("snr_estimate_db", 0)
    print("\nğŸ“Š æ•ˆæœå¯¹æ¯”:")
    print(f"   SNR: {snr_before:.1f} dB -> {snr_after:.1f} dB")
    print(f"   Trend: {quality['has_trend']} -> {quality_after['has_trend']}")

    print("\n" + "=" * 60)
    print("âœ… æ¼”ç¤ºå®Œæˆ")


if __name__ == "__main__":
    demo_cleaning_workflow()
