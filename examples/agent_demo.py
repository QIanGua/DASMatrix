#!/usr/bin/env python3
"""DASMatrix AI Agent é›†æˆç¤ºä¾‹ã€‚

æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•å°† DASMatrix å·¥å…·é›†æˆåˆ° AI Agent å·¥ä½œæµä¸­ã€‚

è¿è¡Œæ–¹å¼:
    uv run python examples/agent_demo.py

ç¯å¢ƒå˜é‡:
    ANTHROPIC_API_KEY: Anthropic API å¯†é’¥ (å¯é€‰ï¼Œç”¨äºçœŸå® API è°ƒç”¨)
    OPENAI_API_KEY: OpenAI API å¯†é’¥ (å¯é€‰)
"""

import json
from pathlib import Path

import numpy as np


def create_demo_data() -> Path:
    """åˆ›å»ºç”¨äºæ¼”ç¤ºçš„åˆæˆ DAS æ•°æ®ã€‚"""
    import h5py

    # ç”Ÿæˆåˆæˆæ•°æ®
    fs = 1000  # é‡‡æ ·ç‡ 1kHz
    duration = 5  # 5 ç§’
    n_channels = 100
    n_samples = fs * duration

    t = np.arange(n_samples) / fs

    # åˆ›å»ºåˆæˆä¿¡å·: 10Hz + 50Hz + å™ªå£°
    data = np.zeros((n_samples, n_channels))
    for ch in range(n_channels):
        signal = (
            np.sin(2 * np.pi * 10 * t)  # 10 Hz æˆåˆ†
            + 0.5 * np.sin(2 * np.pi * 50 * t + ch * 0.1)  # 50 Hz æˆåˆ† (å¸¦ç›¸ç§»)
            + 0.1 * np.random.randn(n_samples)  # å™ªå£°
        )
        # åœ¨æŸäº›é€šé“æ·»åŠ  "äº‹ä»¶"
        if 40 <= ch <= 60:
            event_start = int(2.5 * fs)  # 2.5 ç§’å¤„
            event_duration = int(0.2 * fs)  # 0.2 ç§’
            signal[event_start : event_start + event_duration] += 2 * np.sin(2 * np.pi * 100 * t[:event_duration])
        data[:, ch] = signal

    # ä¿å­˜ä¸º HDF5
    demo_path = Path("/tmp/das_demo_data.h5")
    with h5py.File(demo_path, "w") as f:
        f.create_dataset("data", data=data)
        f.attrs["sampling_rate"] = fs
        f.attrs["n_channels"] = n_channels
        f.attrs["channel_spacing"] = 1.0

    print(f"âœ… åˆ›å»ºæ¼”ç¤ºæ•°æ®: {demo_path}")
    print(f"   å½¢çŠ¶: {data.shape}, é‡‡æ ·ç‡: {fs} Hz, æ—¶é•¿: {duration} ç§’")

    return demo_path


def demo_tool_execution():
    """æ¼”ç¤ºå·¥å…·å‡½æ•°çš„ç›´æ¥è°ƒç”¨ã€‚"""
    print("\n" + "=" * 60)
    print("ğŸ”§ DASMatrix Agent å·¥å…·æ¼”ç¤º - ç›´æ¥è°ƒç”¨æ¨¡å¼")
    print("=" * 60)

    from DASMatrix.agent import DASAgentTools

    # åˆ›å»ºæ¼”ç¤ºæ•°æ®
    demo_path = create_demo_data()

    # åˆå§‹åŒ–å·¥å…·é›†
    tools = DASAgentTools()

    # 1. è¯»å–æ•°æ®
    print("\nğŸ“‚ æ­¥éª¤ 1: è¯»å– DAS æ•°æ®")
    result = tools.read_das_data(str(demo_path))
    print(f"   ç»“æœ: {json.dumps(result, indent=2)}")
    data_id = result["id"]

    # 2. è·å–ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š æ­¥éª¤ 2: è·å–æ•°æ®ç»Ÿè®¡")
    stats = tools.get_data_stats(data_id)
    print(f"   å‡å€¼: {stats['statistics']['mean']:.4f}")
    print(f"   æ ‡å‡†å·®: {stats['statistics']['std']:.4f}")
    print(f"   RMS: {stats['statistics']['rms']:.4f}")

    # 3. ä¿¡å·å¤„ç†
    print("\nğŸ”¬ æ­¥éª¤ 3: åº”ç”¨ä¿¡å·å¤„ç†æµæ°´çº¿")
    processed = tools.process_signal(
        data_id,
        operations=[
            {"op": "detrend"},
            {"op": "bandpass", "low": 5, "high": 80},
            {"op": "normalize", "method": "zscore"},
        ],
        output_name="filtered_data",
    )
    print(f"   å¤„ç†åæ•°æ® ID: {processed['id']}")
    print(f"   åº”ç”¨æ“ä½œ: {processed['pipeline']}")

    # 4. é¢‘è°±åˆ†æ
    print("\nğŸ“ˆ æ­¥éª¤ 4: é¢‘è°±åˆ†æ")
    spectrum = tools.compute_spectrum(data_id, channel=50)
    print(f"   é¢‘ç‡èŒƒå›´: {spectrum['frequency_range']} Hz")
    print(f"   ä¸»å¯¼é¢‘ç‡: {spectrum['dominant_frequency_hz']:.2f} Hz")
    print(f"   å³°å€¼é¢‘ç‡: {[p['frequency_hz'] for p in spectrum['peak_frequencies']]}")

    # 5. äº‹ä»¶æ£€æµ‹
    print("\nğŸ” æ­¥éª¤ 5: äº‹ä»¶æ£€æµ‹")
    events = tools.detect_events(data_id, threshold_db=-20)
    print(f"   æ£€æµ‹åˆ°äº‹ä»¶æ•°: {events['events_detected']}")
    for i, event in enumerate(events["events"][:3]):
        print(
            f"   äº‹ä»¶ {i + 1}: {event['start_time_s']:.3f}s - {event['end_time_s']:.3f}s ({event['duration_ms']:.1f}ms)"
        )

    # 6. å¯è§†åŒ–
    print("\nğŸ¨ æ­¥éª¤ 6: ç”Ÿæˆå¯è§†åŒ–")
    viz = tools.create_visualization(data_id, plot_type="waterfall", output_path="/tmp/das_demo_waterfall.png")
    print(f"   å›¾è¡¨ç±»å‹: {viz['plot_type']}")
    print(f"   ä¿å­˜è·¯å¾„: {viz['output_path']}")

    # 7. ä¼šè¯ç®¡ç†
    print("\nğŸ“‹ æ­¥éª¤ 7: æŸ¥çœ‹ä¼šè¯å¯¹è±¡")
    session_info = tools.list_session_objects()
    print(f"   å½“å‰å¯¹è±¡æ•°: {session_info['count']}")
    for obj_id, info in session_info["objects"].items():
        print(f"   - {obj_id}: {info['type']}, å½¢çŠ¶: {info.get('shape')}")

    print("\n" + "=" * 60)
    print("âœ… æ¼”ç¤ºå®Œæˆ!")
    print("=" * 60)


def demo_simulated_agent_conversation():
    """æ¨¡æ‹Ÿ AI Agent å¯¹è¯æµç¨‹ã€‚"""
    print("\n" + "=" * 60)
    print("ğŸ¤– DASMatrix Agent å·¥å…·æ¼”ç¤º - æ¨¡æ‹Ÿå¯¹è¯æ¨¡å¼")
    print("=" * 60)

    from DASMatrix.agent import DASAgentTools, get_openai_tools

    # åˆ›å»ºæ¼”ç¤ºæ•°æ®
    demo_path = create_demo_data()

    # åˆå§‹åŒ–å·¥å…·é›†
    tools = DASAgentTools()

    # è·å–å·¥å…· schema
    tool_schemas = get_openai_tools()
    print(f"\nğŸ“š å·²æ³¨å†Œ {len(tool_schemas)} ä¸ªå·¥å…·:")
    for schema in tool_schemas:
        print(f"   - {schema['function']['name']}: {schema['function']['description'][:50]}...")

    # æ¨¡æ‹Ÿç”¨æˆ·å¯¹è¯
    conversations = [
        {
            "user": "è¯·å¸®æˆ‘è¯»å– /tmp/das_demo_data.h5 æ–‡ä»¶",
            "tool_call": {
                "name": "read_das_data",
                "arguments": {"path": str(demo_path)},
            },
        },
        {
            "user": "å¯¹æ•°æ®åš 10-60Hz çš„å¸¦é€šæ»¤æ³¢",
            "tool_call": {
                "name": "process_signal",
                "arguments": {
                    "data_id": "<DATA_ID>",  # ä¼šè¢«æ›¿æ¢
                    "operations": [
                        {"op": "detrend"},
                        {"op": "bandpass", "low": 10, "high": 60},
                    ],
                },
            },
        },
        {
            "user": "åˆ†æä¸€ä¸‹ä¸»è¦çš„é¢‘ç‡æˆåˆ†",
            "tool_call": {
                "name": "compute_spectrum",
                "arguments": {"data_id": "<DATA_ID>"},
            },
        },
        {
            "user": "ç”Ÿæˆä¸€ä¸ªç€‘å¸ƒå›¾",
            "tool_call": {
                "name": "create_visualization",
                "arguments": {"data_id": "<DATA_ID>", "plot_type": "waterfall"},
            },
        },
    ]

    data_id = None

    print("\n--- å¯¹è¯å¼€å§‹ ---\n")

    for conv in conversations:
        print(f"ğŸ‘¤ ç”¨æˆ·: {conv['user']}")

        # æ›¿æ¢ DATA_ID å ä½ç¬¦
        # æ›¿æ¢ DATA_ID å ä½ç¬¦
        tool_call = conv["tool_call"]
        if not isinstance(tool_call, dict) or "arguments" not in tool_call or "name" not in tool_call:
            continue

        args = tool_call["arguments"]
        if isinstance(args, dict):
            args = args.copy()
            if "data_id" in args and args["data_id"] == "<DATA_ID>":
                args["data_id"] = data_id

        # æ‰§è¡Œå·¥å…·è°ƒç”¨
        tool_name = tool_call["name"]
        if not isinstance(tool_name, str):
            continue

        if not hasattr(tools, tool_name):
            continue

        method = getattr(tools, tool_name)
        if isinstance(args, dict):
            result = method(**args)
        else:
            result = method()

        # ä¿å­˜ data_id ä¾›åç»­ä½¿ç”¨
        if "id" in result and tool_name == "read_das_data":
            data_id = result["id"]

        print(f"ğŸ”§ å·¥å…·è°ƒç”¨: {tool_name}")
        print(f"   å‚æ•°: {json.dumps(args, ensure_ascii=False)}")
        print(f"   ç»“æœ: {json.dumps(result, indent=2, ensure_ascii=False)[:200]}...")

        if tool_name == "read_das_data":
            print(f"ğŸ¤– Agent: å·²æˆåŠŸè¯»å–æ•°æ®ï¼Œå…± {result['n_channels']} ä¸ªé€šé“ï¼Œæ—¶é•¿ {result['duration']:.1f} ç§’ã€‚")
        elif tool_name == "process_signal":
            print(f"ğŸ¤– Agent: å·²å®Œæˆæ»¤æ³¢å¤„ç†ï¼Œåº”ç”¨äº† {result['operations_applied']} ä¸ªæ“ä½œã€‚")
        elif tool_name == "compute_spectrum":
            print(f"ğŸ¤– Agent: é¢‘è°±åˆ†æå®Œæˆï¼Œä¸»å¯¼é¢‘ç‡ä¸º {result['dominant_frequency_hz']:.1f} Hzã€‚")
        elif tool_name == "create_visualization":
            print(f"ğŸ¤– Agent: å·²ç”Ÿæˆ{result['plot_type']}å›¾ï¼Œä¿å­˜åœ¨ {result['output_path']}")

        print()

    print("--- å¯¹è¯ç»“æŸ ---\n")


def print_tool_schemas():
    """æ‰“å°å·¥å…· Schema (ç”¨äºå¤åˆ¶åˆ° API è°ƒç”¨)ã€‚"""
    from DASMatrix.agent.schemas import get_anthropic_tools, get_openai_tools

    print("\n" + "=" * 60)
    print("ğŸ“‹ OpenAI Function Calling Schema")
    print("=" * 60)
    print(json.dumps(get_openai_tools(), indent=2, ensure_ascii=False))

    print("\n" + "=" * 60)
    print("ğŸ“‹ Anthropic Tool Use Schema")
    print("=" * 60)
    print(json.dumps(get_anthropic_tools(), indent=2, ensure_ascii=False))


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="DASMatrix AI Agent é›†æˆç¤ºä¾‹")
    parser.add_argument(
        "--mode",
        choices=["direct", "conversation", "schema"],
        default="direct",
        help="æ¼”ç¤ºæ¨¡å¼: direct(ç›´æ¥è°ƒç”¨), conversation(æ¨¡æ‹Ÿå¯¹è¯), schema(æ‰“å°Schema)",
    )
    args = parser.parse_args()

    if args.mode == "direct":
        demo_tool_execution()
    elif args.mode == "conversation":
        demo_simulated_agent_conversation()
    elif args.mode == "schema":
        print_tool_schemas()
